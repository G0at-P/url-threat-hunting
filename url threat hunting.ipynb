{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from nltk.util import ngrams\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "import baker\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "matplotlib.use('pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mmh3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(file,target,col_1,col_2,col_3):\n",
    "   ## generate random seeds for reproducibility\n",
    "    np.random.seed(3)\n",
    "\n",
    "   ## import data from two sources as dataframes\n",
    "    data = pd.read_csv(file)\n",
    "    y_label= np.array(data[target].values.astype(int))\n",
    "    data[col_1]=[extract_tokens(i) for i in data[col_1]]\n",
    "    data[col_2]=[extract_host(i) for i in data[col_2]]\n",
    "    data[col_2]=[i[::-1] for i in data[col_2]]\n",
    "    data[col_3]=data[col_1]+data[col_2]\n",
    "    \n",
    "    ## filter out any null values in target variable\n",
    "    bool_series = pd.notnull(data[target]) \n",
    "    data=data[bool_series] \n",
    "    \n",
    "    ## 70/30 training and testing split on data \n",
    "    X=np.array(eng_hash(data[col_3].values))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size=0.3)\n",
    "    \n",
    "    ## transform training and testing set into vectors with pre-fixed dimensions\n",
    "    X_train=X_train.reshape(X_train.shape[0],X_train.shape[2])\n",
    "    X_test=X_test.reshape(X_test.shape[0],X_test.shape[2])\n",
    "    \n",
    "    return (X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tokens(element):\n",
    "    tokens=str(element).rsplit(\"/\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_host(element):\n",
    "    host=str(element).rsplit(\".\")\n",
    "    return host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_hash(data, vdim=1000):\n",
    "    ## take 3 n-gram of the url and hash it into a vector of length 1000\n",
    "    final = []\n",
    "    for url in data:\n",
    "        v = [0] * vdim\n",
    "        new = list(ngrams(url, 3))\n",
    "        for i in new:\n",
    "            new_ = ''.join(i)\n",
    "            idx = mmh3.hash(new_) % vdim\n",
    "            v[idx] += 1\n",
    "        final.append([np.array(v)])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    # a class will capture the training loss\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model():\n",
    "    model = Sequential()\n",
    " \n",
    "    ## hidden layers with dropout rate=0.15 and batchnormalization to prevent overfitting issues\n",
    "    model.add(Dense(128, input_dim=1000))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.15))\n",
    "        \n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.15))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.15))\n",
    "\n",
    "    ## final output layer for binary classification problem\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    ## loss function: crossentropy, optimization_procedure: stochastic gradient descent, metrics: accuracy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model):\n",
    "    log.info(\"Beginning training model\")\n",
    "    loss = LossHistory()\n",
    "    model.fit(X_train, y_train,\n",
    "              epochs=20,\n",
    "              batch_size=128, verbose=1, callbacks=[loss])\n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    ## find the nearest value in an array to the given value\n",
    "    return (np.abs(array-value)).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(actual, preds):   \n",
    "    ## calculate the count of actual and preds\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for y, pred in zip(actual, preds):\n",
    "        if pred == 1 and y == 1:\n",
    "            tp += 1\n",
    "        if pred == 0 and y == 1:\n",
    "            fn += 1\n",
    "        if pred == 1 and y == 0:\n",
    "            fp += 1\n",
    "        if pred == 0 and y == 0:\n",
    "            tn += 1\n",
    "    return np.column_stack((tp, fp, tn, fn)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(X_train,y_train,X_test,y_test):\n",
    "    preds=  model.predict(X_test, batch_size=64)\n",
    "    \n",
    "    ## ensure format of preds is able to be handled by sklearn\n",
    "    if len(preds.shape)==1:\n",
    "        preds_ = np.array([preds]).T\n",
    "        \n",
    "    if preds.shape[1]==1:\n",
    "        p_neg = 1.0-preds\n",
    "        preds_ = np.hstack((p_neg, preds))\n",
    "        preds_ = preds_.astype(np.float)\n",
    "    \n",
    "    ## get roc curve using sklearn\n",
    "    results = {}\n",
    "    fpr, tpr, thresh = roc_curve(y_test, preds_[:,1], 1.0)\n",
    "    curr_auc = auc(fpr, tpr)\n",
    "    results['roc'] = np.column_stack((fpr, tpr, thresh)).tolist()\n",
    "    results['auc'] = np.array([curr_auc]).tolist()\n",
    "    \n",
    "    ## return false positive rate and true positive rate\n",
    "    fpr=[x[0] for x in results['roc']]\n",
    "    tpr=[x[1] for x in results['roc']]\n",
    "    \n",
    "    labels=['Deep Learning w/time Split']\n",
    "    plt.plot(np.logspace(-10,0, 1000), np.logspace(-10,0, 1000), 'k--')\n",
    "    plt.xlim([0,1.0])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC')\n",
    "    plt.step(fpr,tpr,linestyle='-',color='blue',label='Model {}  (AUC = {:0.4f}), '.format(labels[0], results['auc'][0]))\n",
    "    plt.legend(loc='lower right',prop={'size':8})\n",
    "    plt.xlim([1e-6, 1])\n",
    "    plt.xscale('log')\n",
    "    plt.savefig('ROC_fig.png',dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
